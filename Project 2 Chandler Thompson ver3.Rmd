---
title: "Project 2 Chandler Thompson"
author: "Chandler Thompson"
date: "2/28/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Library necessary packages

```{r}

library(caret)
library(mlbench)

```


Data

#load the mlbench package which has the BreastCancer data set
require(mlbench)

# if you don't have any required package, use the install.packages() command
# load the data set
data(BreastCancer)


Read in our data

```{r}

data("BreastCancer")

# some algorithms don't like missing values, so remove rows with missing values
BreastCancer <- na.omit(BreastCancer)

# remove the unique identifier, which is useless and would confuse the machine learning algorithms
BreastCancer$Id <- NULL 


# partition the data set for 80% training and 20% evaluation (adapted from ?randomForest)
set.seed(2)

SampleIndex <- sample(2, nrow(BreastCancer), replace = TRUE, prob=c(0.8, 0.2))


```


Basic summary exploration of our data

```{r}

BreastCancer <- cbind(BreastCancer[10],BreastCancer[1:9])

str(BreastCancer)

summary(BreastCancer)

```

Recursive Partitioning


```{r}

# create model using recursive partitioning on the training data set
library(rpart)
x.rp <- rpart(Class ~ ., data=BreastCancer[SampleIndex == 1,])
# predict classes for the evaluation data set
x.rp.pred <- predict(x.rp, type="class", newdata=BreastCancer[SampleIndex == 2,])
# score the evaluation data set (extract the probabilities)
x.rp.prob <- predict(x.rp, type="prob", newdata=BreastCancer[SampleIndex == 2,])

#plot.new()

plot(x.rp, main="Decision tree created using rpart") ; text(x.rp)

```

Conditional Inference Tree

```{r}

library(party)
x.ct <- ctree(Class ~ ., data=BreastCancer[SampleIndex == 1,])
x.ct.pred <- predict(x.ct, newdata=BreastCancer[SampleIndex == 2,])
x.ct.prob <-  1- unlist(treeresponse(x.ct, BreastCancer[SampleIndex == 2,]), use.names=F)[seq(1,nrow(BreastCancer[SampleIndex == 2,])*2,2)]

plot(x.ct, main="Decision tree created using condition inference trees")

```


Random Forest 

```{r}

# create model using random forest and bagging ensemble using conditional inference trees
x.cf <- cforest(Class ~ ., data=BreastCancer[SampleIndex == 1,], control = cforest_unbiased(mtry = ncol(BreastCancer)-2))
x.cf.pred <- predict(x.cf, newdata=BreastCancer[SampleIndex == 2,])
x.cf.prob <-  1- unlist(treeresponse(x.cf, BreastCancer[SampleIndex == 2,]), use.names=F)[seq(1,nrow(BreastCancer[SampleIndex == 2,])*2,2)]

```


Bagging Ensemble

```{r}

# create model using bagging (bootstrap aggregating)
library(ipred)
x.ip <- bagging(Class ~ ., data=BreastCancer[SampleIndex == 1,])
x.ip.prob <- predict(x.ip, type="prob", newdata=BreastCancer[SampleIndex == 2,])


```

Support Vector Machine

```{r}

# create model using svm (support vector machine)
library(e1071)

# svm requires tuning
x.svm.tune <- tune(svm, Class~., data = BreastCancer[SampleIndex == 1,],
                   ranges = list(gamma = 2^(-8:1), cost = 2^(0:4)),
                   tunecontrol = tune.control(sampling = "fix"))

# display the tuning results (in text format)
x.svm.tune
# If the tuning results are on the margin of the parameters (e.g., gamma = 2^-8), 
# then widen the parameters.
# I manually copied the cost and gamma from console messages above to parameters below.
x.svm <- svm(Class~., data = BreastCancer[SampleIndex == 1,], cost=4, gamma=0.0625, probability = TRUE)
x.svm.prob <- predict(x.svm, type="prob", newdata=BreastCancer[SampleIndex == 2,], probability = TRUE)

```

Plot ROC curves to compare our classifiers

```{r}

##
## plot ROC curves to compare the performance of the individual classifiers
##

# Output the plot to a PNG file for display on web.  To draw to the screen, 
# comment this line out.
# png(filename="roc_curve_5_models.png", width=700, height=700)



# load the ROCR package which draws the ROC curves
library(ROCR)

# create an ROCR prediction object from rpart() probabilities
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[SampleIndex == 2,'Class'])

# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")

# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")

# Draw a legend.
legend(0.6, 0.6, c('rpart', 'ctree', 'cforest','bagging','svm'), 2:6)


# ctree
x.ct.prob.rocr <- prediction(x.ct.prob, BreastCancer[SampleIndex == 2,'Class'])
x.ct.perf <- performance(x.ct.prob.rocr, "tpr","fpr")

# add=TRUE draws on the existing chart 
plot(x.ct.perf, col=3, add=TRUE)


# cforest
x.cf.prob.rocr <- prediction(x.cf.prob, BreastCancer[SampleIndex == 2,'Class'])
x.cf.perf <- performance(x.cf.prob.rocr, "tpr","fpr")

plot(x.cf.perf, col=4, add=TRUE)

# bagging
x.ip.prob.rocr <- prediction(x.ip.prob[,2], BreastCancer[SampleIndex == 2,'Class'])
x.ip.perf <- performance(x.ip.prob.rocr, "tpr","fpr")

plot(x.ip.perf, col=5, add=TRUE)

# svm
x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], BreastCancer[SampleIndex == 2,'Class'])
x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")
plot(x.svm.perf, col=6, add=TRUE)

# Close and save the PNG file.
#dev.off()


```

Bagging and SVM appear to perform the best.



#### Compare classifiers from provided R file

SVM

```{r}

library(e1071)
mysvm <- svm(Class ~ ., BreastCancer)
mysvm.pred <- predict(mysvm, BreastCancer)
table(mysvm.pred,BreastCancer$Class)

length(mysvm.pred)
length(BreastCancer$Class)


```
Naive Bayes

```{r}

library(klaR)
mynb <- NaiveBayes(Class ~ ., BreastCancer)
mynb.pred <- predict(mynb,BreastCancer)
table(mynb.pred$class,BreastCancer$Class)

```

Neural Net

```{r}

library(nnet)
mynnet <- nnet(Class ~ ., BreastCancer, size=1)
mynnet.pred <- predict(mynnet,BreastCancer,type="class")
table(mynnet.pred,BreastCancer$Class)

```

Decision Tree

```{r}

#Decision trees
library(rpart)
mytree <- rpart(Class ~ ., BreastCancer)
plot(mytree); text(mytree) # in "iris_tree.ps"
summary(mytree)
mytree.pred <- predict(mytree,BreastCancer,type="class")
table(mytree.pred,BreastCancer$Class)

```

Leave 1 Out Cross Validation

```{r}

# Leave-1-Out Cross Validation (LOOCV)
ans <- numeric(length(BreastCancer[,1]))
for (i in 1:length(BreastCancer[,1])) {
  mytree <- rpart(Class ~ ., BreastCancer[-i,])
  mytree.pred <- predict(mytree,BreastCancer[i,],type="class")
  ans[i] <- mytree.pred
}
ans <- factor(ans,labels=levels(BreastCancer$Class))
table(ans,BreastCancer$Class)
# The same as above in this case


```

Quadratic Discriminant Analysis

```{r}

#Quadratic Discriminant Analysis
library(MASS)

BreastCancerInts <- BreastCancer

BreastCancerInts$Cl.thickness <- as.integer(BreastCancerInts$Cl.thickness)
BreastCancerInts$Cl.thickness <- as.integer(BreastCancerInts$Cl.thickness)
BreastCancerInts$Cell.size <- as.integer(BreastCancerInts$Cell.size)
BreastCancerInts$Cell.shape <- as.integer(BreastCancerInts$Cell.shape)
BreastCancerInts$Marg.adhesion <- as.integer(BreastCancerInts$Marg.adhesion)
BreastCancerInts$Epith.c.size <- as.integer(BreastCancerInts$Epith.c.size)
BreastCancerInts$Bare.nuclei <- as.integer(BreastCancerInts$Bare.nuclei)
BreastCancerInts$Bl.cromatin <- as.integer(BreastCancerInts$Bl.cromatin)
BreastCancerInts$Normal.nucleoli <- as.integer(BreastCancerInts$Normal.nucleoli)
BreastCancerInts$Mitoses <- as.integer(BreastCancerInts$Mitoses)

myqda <- qda(Class ~ ., BreastCancerInts)
myqda.pred <- predict(myqda, BreastCancerInts)
table(myqda.pred$class,BreastCancerInts$Class)


```

Regularized Discriminant Analysis

```{r}

#Regularised Discriminant Analysis
library(klaR)
myrda <- rda(Class ~ ., BreastCancer)
myrda.pred <- predict(myrda, BreastCancer)
table(myrda.pred$class,BreastCancer$Class)


```

Random Forests

```{r}

#Random Forests
library(randomForest)
myrf <- randomForest(Class ~ .,BreastCancer)
myrf.pred <- predict(myrf, BreastCancer)
table(myrf.pred, BreastCancer$Class)

```


Ensemble

Now we will combine our different predictions and use a 'majority vote' between the predictions to assign our final prediction.


```{r}

combine.classes<-data.frame(myrf.pred, myrda.pred$class,myqda.pred,
mytree.pred,mynnet.pred,mysvm.pred, mynb.pred$class)

combine.classes$myrf.pred<-ifelse(combine.classes$myrf.pred=="benign", 0, 1)
combine.classes[,2]<-ifelse(combine.classes[,2]=="benign", 0, 1)
combine.classes[,3]<-ifelse(combine.classes[,3]=="benign", 0, 1)
combine.classes[,4]<-ifelse(combine.classes[,4]=="benign", 0, 1)
combine.classes[,5]<-ifelse(combine.classes[,5]=="benign", 0, 1)
combine.classes[,6]<-ifelse(combine.classes[,6]=="benign", 0, 1)
combine.classes[,7]<-ifelse(combine.classes[,7]=="benign", 0, 1)
combine.classes[,8]<-ifelse(combine.classes[,8]=="benign", 0, 1)
combine.classes[,9]<-ifelse(combine.classes[,9]=="benign", 0, 1)

combine.classes$MajorityVote <- rowSums(combine.classes)

combine.classes$MajorityVote <-ifelse(combine.classes$MajorityVote >= 5, "malignant", "benign")

table(combine.classes$MajorityVote, BreastCancer$Class)

confusionMatrix(as.factor(combine.classes$MajorityVote), BreastCancer$Class)


```

We can see that with our ensemble method we achieve a 97.8% accuracy with similarly high sensitivity and specificity.









